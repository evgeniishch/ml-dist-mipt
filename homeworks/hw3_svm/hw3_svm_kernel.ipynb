{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ядра для SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В этом задании мы попрактикуемся в написании ядер для SVM, в частности напишем rbf-ядро.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Если вы работаете в Google Colab, раскомментируйте строку ниже чтобы скачать файл `svm.py`\n",
    "'''\n",
    "# !wget https://raw.githubusercontent.com/evgeniishch/ml-dist-mipt/main/homeworks/hw3_svm/svm.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# use seaborn plotting defaults\n",
    "import seaborn as sns; sns.set()\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_svc_decision_function(model, ax=None, plot_support=True):\n",
    "    \"\"\"Plot the decision function for our SVM class\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    xlim = ax.get_xlim()\n",
    "    ylim = ax.get_ylim()\n",
    "    # create grid to evaluate model\n",
    "    x = np.linspace(xlim[0], xlim[1], 50)\n",
    "    y = np.linspace(ylim[0], ylim[1], 50)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    xy = np.vstack([X.ravel(), Y.ravel()]).T\n",
    "    P = model.predict(xy).reshape(X.shape)\n",
    "    # plot decision boundary and margins\n",
    "    CS = ax.contourf(X, Y, P, origin='lower', cmap='autumn', alpha=0.1)\n",
    "    plt.colorbar(CS, ax=ax, shrink=0.8, extend='both')\n",
    "    # plot support vectors\n",
    "    if plot_support:\n",
    "        ax.scatter(model.support_vectors_[:, 0],\n",
    "                   model.support_vectors_[:, 1],\n",
    "                   s=300, linewidth=1, facecolors='none');\n",
    "    ax.set_xlim(xlim)\n",
    "    ax.set_ylim(ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles\n",
    "\n",
    "from sklearn.svm import SVC # \"Support vector classifier\"\n",
    "\n",
    "X, y = make_circles(150, factor=.1, noise=.1, random_state=42)\n",
    "\n",
    "X_test, y_test = X[100:], y[100:]\n",
    "X, y = X[:100], y[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn realization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='linear').fit(X, y)\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, pred))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "plot_svc_decision_function(clf, plot_support=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(kernel='rbf').fit(X, y)\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, pred))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "plot_svc_decision_function(clf, plot_support=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим на нашу реализацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вам необходимо заполнить пропуски в файле svm.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Прмяую__ задачу оптимизации для SVM можно сформулировать как\n",
    "\n",
    "$$ \\frac{1}{n} \\sum_{i=1}^n \\max(0, 1 - y_i (w X_i - b)) + \\lambda ||w||_2 \\to \\min_w $$\n",
    "\n",
    "Эту задачу можно решить с помощью градиентных или суб-градиентных методов.\n",
    "\n",
    "-----\n",
    "В свою очередь __двойственная__ задача оптимизации имеет вид:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n c_i - \\frac{1}{2} \\sum_{i=1}^n \\sum_{j=1}^n y_i c_i (X_i \\cdot X_j ) y_j c_j \\to \\max_{c_1,...,c_n} \\\\ \\text{при условии} \\\\\n",
    "\\sum_{i=1}^n c_iy_i=0 \\\\\n",
    "0 \\leq c_i \\leq \\frac{1}{2n\\lambda} \\forall i\n",
    "$$\n",
    "\n",
    "Где $W = \\sum_{i=1}^n c_i y_i X_i$.\n",
    "\n",
    "В этой задаче квадратичного программирования мы можем сипользовать kernel trick: <br/>\n",
    "рассмотрим функцию $K(X_i, X_j) = \\phi (X_i) \\phi (X_j)$ и заменим скалярные произведения в нашей задаче оптимизации\n",
    "\n",
    "Мы получим \n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^n c_i - \\frac{1}{2} \\sum_{i=1}^n \\sum_{j=1}^n y_i c_i K(X_i, X_j) y_j c_j \\to \\max_{c_1,...,c_n} \\\\\n",
    "\\text{при условии} \\\\\n",
    "\\sum_{i=1}^n c_iy_i=0 \\\\\n",
    "0 \\leq c_i \\leq \\frac{1}{2n\\lambda} \\forall i\n",
    "$$\n",
    "\n",
    "$W = \\sum_{i=1}^n c_i y_i \\phi(X_i)$\n",
    "\n",
    "----\n",
    "При этом прямая задача оптимизации с ядром может быть сформулирована как (см. [Olivier Chapelle, 2006](https://www.cs.utah.edu/~piyush/teaching/svm-solving-primal.pdf)):\n",
    "\n",
    "$$f(x) = \\sum_{i=1}^n \\beta_i K(x_i, x)$$\n",
    "\n",
    "$$K: K_{i,j} = K(x_i, x_j)$$\n",
    "\n",
    "$$ \\lambda \\vec{\\beta^T} K \\vec{\\beta} + \\sum_{i=1}^n L(y_i, K_i^T \\vec{\\beta}) \\to \\min_{\\vec{\\beta}}$$\n",
    "\n",
    "где L это Hinge loss: $L(y_i, K_i^T \\vec{\\beta}) = \\max(0, 1 - y_i (K_i^T \\vec{\\beta}))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ядро Radial basis function.\n",
    "\n",
    "####  Функция ядра RBF для двух объектов x and x', представленных векторами признаков в некотором пространстве, может быть определена как:\n",
    "\n",
    "## $K(x,x') = \\exp \\big{[}- \\frac{||x-x'||^2}{2 \\sigma^2} \\big{]}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверим себя:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svm import SVM\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y==0] = -1 # for convenience with formulas\n",
    "y_test[y_test==0] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVM(epochs=3, lr=1, batch_size=20, verbose=True)\n",
    "clf.fit(X, y)\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, pred))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "plot_svc_decision_function(clf, plot_support=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVM(epochs=100, lr=0.1, batch_size=20, verbose=True, kernel_function=SVM.rbf)\n",
    "clf.fit(X, y)\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, pred))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='autumn')\n",
    "plot_svc_decision_function(clf, plot_support=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert accuracy_score(y_test, pred) > 0.95"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our model with rbf kernel can learn this dataset too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
