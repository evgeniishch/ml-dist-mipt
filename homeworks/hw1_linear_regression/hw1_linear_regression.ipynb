{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейная регрессия и градиентный спуск\n",
    "\n",
    "В этом задании вам необходимо реализовать функции MSE, MAE, L1 и L2 регуляризации и их производные соответственно. Сделать это необходимо в векторной форме (используйте всю мощь библиотеки numpy!). Векторизация операций еще пригодится нам в будущем при реализации нейронных сетей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "If you are using Google Colab, uncomment the next lines to download `loss_and_derivatives.py` and `boston_subset.json`\n",
    "You can open and change downloaded `.py` files in Colab using the \"Files\" sidebar on the left.\n",
    "'''\n",
    "# !wget https://github.com/evgeniishch/ml-dist-mipt/raw/main/homeworks/hw1_linear_regression/boston_subset.json\n",
    "# !wget https://github.com/evgeniishch/ml-dist-mipt/blob/main/homeworks/hw1_linear_regression/loss_and_derivatives.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8lQUR89nGE1f"
   },
   "outputs": [],
   "source": [
    "# Run some setup code for this notebook.\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OGf3ShTNGE1q"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('boston_subset.json', 'r') as iofile:\n",
    "    dataset = json.load(iofile)\n",
    "feature_matrix = np.array(dataset['data'])\n",
    "targets = np.array(dataset['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WbBc_5FhGE2B"
   },
   "source": [
    "## Реализация функционалов потерь и их производных\n",
    "Вам необходимо реализовать методы в файле `loss_and_derivatives.py`.\n",
    "__В этом задании мы игнорируем свободный член (bias term)__, поэтому линейная модель будет иметь вид \n",
    "$$\n",
    "\\hat{\\mathbf{y}} = XW\n",
    "$$\n",
    "где в матрице $X$ отсутствует фиктивный вектор из единиц.\n",
    "\n",
    "Реализуйте функционалы потерь, регуляризации и их производные по весам $W$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ячейка ниже позволяет автоматически подгружать изменения в файле `loss_and_derivatives.py` в этот ноутбук. Не забывайте сохранять изменения в файле перед тем, как переподгружать функции!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dtELlRTOGE2E",
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "# This dirty hack might help if the autoreload has failed for some reason\n",
    "try:\n",
    "    del LossAndDerivatives\n",
    "except:\n",
    "    pass\n",
    "\n",
    "from loss_and_derivatives import LossAndDerivatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обратите внимание, что мы решаем задачу для общего случая и наши целевые переменные это тоже векторы. Поэтому при вычислении метрик необходимо усреднять ошибку по всем размерностям. Для лучшего понимания мы уже реализовали метод `mse()`, посмотрите как он работает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "71VCxUwHGE2L"
   },
   "outputs": [],
   "source": [
    "w = np.array([1., 1.])\n",
    "x_n, y_n = feature_matrix, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sMN81aYyGE2T"
   },
   "source": [
    "Проверки ниже помогут проверить что вы заполнили методы в файле `loss_and_derivatives.py` правильно. Убедитесь, что ваше решение проходит все ассерты перед отправкой!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KKUYnPWuGE2V"
   },
   "outputs": [],
   "source": [
    "w = np.array([1., 1.])\n",
    "x_n, y_n = feature_matrix, targets\n",
    "\n",
    "# Repeating data to make everything multi-dimentional\n",
    "w = np.vstack([w[None, :] + 0.27, w[None, :] + 0.22, w[None, :] + 0.45, w[None, :] + 0.1]).T\n",
    "y_n = np.hstack([y_n[:, None], 2*y_n[:, None], 3*y_n[:, None], 4*y_n[:, None]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 477
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1344,
     "status": "error",
     "timestamp": 1582397124081,
     "user": {
      "displayName": "Victor Yacovlev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDahDnBQR6_kQQX4xt7llKTI0xt2Z802bvVR4MrqA=s64",
      "userId": "11689260236152306260"
     },
     "user_tz": -180
    },
    "id": "UtkO4hWYGE2c",
    "outputId": "cb0b99a8-2db4-4873-dfd8-741b52db29f3"
   },
   "outputs": [],
   "source": [
    "reference_mse_derivative = np.array([\n",
    "    [ 7.32890068, 12.88731311, 18.82128365, 23.97731238],\n",
    "    [ 9.55674399, 17.05397661, 24.98807528, 32.01723714]\n",
    "])\n",
    "reference_l2_reg_derivative = np.array([\n",
    "    [2.54, 2.44, 2.9 , 2.2 ],\n",
    "    [2.54, 2.44, 2.9 , 2.2 ]\n",
    "])\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_mse_derivative,\n",
    "    LossAndDerivatives.mse_derivative(x_n, y_n, w), rtol=1e-3\n",
    "), 'Something wrong with MSE derivative'\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_l2_reg_derivative,\n",
    "    LossAndDerivatives.l2_reg_derivative(w), rtol=1e-3\n",
    "), 'Something wrong with L2 reg derivative'\n",
    "\n",
    "print(\n",
    "    'MSE derivative:\\n{} \\n\\nL2 reg derivative:\\n{}'.format(\n",
    "        LossAndDerivatives.mse_derivative(x_n, y_n, w),\n",
    "        LossAndDerivatives.l2_reg_derivative(w))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_mae_derivative = np.array([\n",
    "    [0.19708867, 0.19621798, 0.19621798, 0.19572906],\n",
    "    [0.25574138, 0.25524507, 0.25524507, 0.25406404]\n",
    "])\n",
    "reference_l1_reg_derivative = np.array([\n",
    "    [1., 1., 1., 1.],\n",
    "    [1., 1., 1., 1.]\n",
    "])\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_mae_derivative,\n",
    "    LossAndDerivatives.mae_derivative(x_n, y_n, w), rtol=1e-3\n",
    "), 'Something wrong with MAE derivative'\n",
    "\n",
    "assert np.allclose(\n",
    "    reference_l1_reg_derivative,\n",
    "    LossAndDerivatives.l1_reg_derivative(w), rtol=1e-3\n",
    "), 'Something wrong with L1 reg derivative'\n",
    "\n",
    "print(\n",
    "    'MAE derivative:\\n{} \\n\\nL1 reg derivative:\\n{}'.format(\n",
    "        LossAndDerivatives.mae_derivative(x_n, y_n, w),\n",
    "        LossAndDerivatives.l1_reg_derivative(w))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJcSPj8UGE20"
   },
   "source": [
    "### Градиентный спуск на реальных данных\n",
    "Ниже реализован алгоритм градиентного спуска."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "On6aSWuIGE21"
   },
   "outputs": [],
   "source": [
    "def get_w_by_grad(X, Y, w_0, loss_mode='mse', reg_mode=None, lr=0.05, n_steps=100, reg_coeff=0.05):\n",
    "    if loss_mode == 'mse':\n",
    "        loss_function = LossAndDerivatives.mse\n",
    "        loss_derivative = LossAndDerivatives.mse_derivative\n",
    "    elif loss_mode == 'mae':\n",
    "        loss_function = LossAndDerivatives.mae\n",
    "        loss_derivative = LossAndDerivatives.mae_derivative\n",
    "    else:\n",
    "        raise ValueError('Unknown loss function. Available loss functions: `mse`, `mae`')\n",
    "    \n",
    "    if reg_mode is None:\n",
    "        reg_function = LossAndDerivatives.no_reg\n",
    "        reg_derivative = LossAndDerivatives.no_reg_derivative # lambda w: np.zeros_like(w)\n",
    "    elif reg_mode == 'l2':\n",
    "        reg_function = LossAndDerivatives.l2_reg\n",
    "        reg_derivative = LossAndDerivatives.l2_reg_derivative\n",
    "    elif reg_mode == 'l1':\n",
    "        reg_function = LossAndDerivatives.l1_reg\n",
    "        reg_derivative = LossAndDerivatives.l1_reg_derivative\n",
    "    else:\n",
    "        raise ValueError('Unknown regularization mode. Available modes: `l1`, `l2`, None')\n",
    "    \n",
    "    \n",
    "    w = w_0.copy()\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        empirical_risk = loss_function(X, Y, w) + reg_coeff * reg_function(w)\n",
    "        gradient = loss_derivative(X, Y, w) + reg_coeff * reg_derivative(w)\n",
    "        gradient_norm = np.linalg.norm(gradient)\n",
    "        if gradient_norm > 5.:\n",
    "            gradient = gradient / gradient_norm * 5.\n",
    "        w -= lr * gradient\n",
    "        \n",
    "        if i % 25 == 0:\n",
    "            print('Step={}, loss={},\\ngradient values={}\\n'.format(i, empirical_risk, gradient))\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим как он работает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1pyDIyqGE25"
   },
   "outputs": [],
   "source": [
    "# Initial weight matrix\n",
    "w = np.ones((2,1), dtype=float)\n",
    "y_n = targets[:, None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "erTRQiAFGE29"
   },
   "outputs": [],
   "source": [
    "w_grad = get_w_by_grad(x_n, y_n, w, loss_mode='mse', reg_mode='l2', n_steps=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение с `sklearn`\n",
    "Давайте сравним нашу реализацию с `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Ridge(alpha=0.05)\n",
    "lr.fit(x_n, y_n)\n",
    "print('sklearn linear regression implementation delivers MSE = {}'.format(np.mean((lr.predict(x_n) - y_n)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gse1m4nyGE3C"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x_n[:, -1], y_n[:, -1])\n",
    "plt.scatter(x_n[:, -1], x_n.dot(w_grad)[:, -1], color='orange', label='Handwritten linear regression', linewidth=5)\n",
    "plt.scatter(x_n[:, -1], lr.predict(x_n), color='cyan', label='sklearn Ridge')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the solutions may look like a bit different, remember, that handwritten linear regression was unable to fit the bias term, it was equal to $0$ by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хоть решения и выглядят немного по разному, не стоит забывать, что в нашей модели мы игнорировали свободный член (то есть он был равен 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GgeWdBmGE3H"
   },
   "source": [
    "### Отправьте решение\n",
    "To submit your work you need to log into Yandex contest (link will be provided later) and upload the `loss_and_derivatives.py` file for the corresponding problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для отправки решения вам необходимо зарегистрироваться в системе Яндекс.Контест по ссылке из репозитория и загрузить файл `loss_and_derivatives.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "assignment0_02_linear_regression_and_gradient_descent.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
